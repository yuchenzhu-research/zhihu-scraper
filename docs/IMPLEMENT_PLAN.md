# 📋 实现计划 (Implementation Plan) - v2.x 升级路线图

> 目标：从“浏览器渲染层归档工具”进化为“纯协议层知乎垂直爬虫及收藏监控系统”。

---

## 阶段一：纯协议层 API 抓包探索 (方向一) - ✅ 已完成
**优先级**：P0  
**目标**：脱离 Playwright 的沉重负载，直接用 Python HttpClient (`curl_cffi`) 抓取知乎的内部 JSON 数据。
*   **Step 1**: 成功定位 `v4/answers` 和 `v4/questions/*/answers` API。 - ✅
*   **Step 2**: 集成 `z_core.js` 并通过 `execjs` 实现 `x-zse-96` 动态签名。 - ✅
*   **Step 3**: 重构 `ZhihuDownloader`，全面抛弃浏览器，实现极轻量化抓取。 - ✅
*   **遗留问题**：专栏文章 (Zhuanlan) 针对纯 API 访问有高级风控 (403/10003)，暂未攻克。

## 阶段二：收藏夹 / 话题增量监控 (方向二) - 🔄 进行中
**优先级**：P1
**目标**：针对收藏夹做低频、增量的高价值内容抓取。
*   **Step 1**: 分析“知乎收藏夹” API (`v4/collections/.../items`) 的翻页逻辑。
*   **Step 2**: 编写 `CollectionMonitor` 任务脚本，实现“发现新增 -> 自动抓取”闭环。
*   **Step 3**: 集成到 CLI 命令中，支持 `zhihu monitor --id 12345`。

## 阶段三：引入 SQLite 轻量化数据存储 (方向三) - ⏳ 待开始
**优先级**：P1
**目标**：不再单纯拉取 Markdown，而是放入本地数据库进行结构化管理。
*   **Step 1**: 开发 `core/db.py` 模块，设计 `articles` 表结构。
*   **Step 2**: 实现“抓取即入库”逻辑。
*   **Step 3**: 解决数据排重逻辑（基于 `answer_id`）。

## 阶段四：代理池与 Cookie 寿命管理池 (方向四)
**优先级**：P3 (当前极低，暂且搁置)
**目标**：处理大规模高并发爬取时的风控对抗。
*   **解释**：当单 IP/单账号被封时，通过代码自动切换其他 IP 甚至购买的代理服务。目前在监控模式下暂时不需要，可以未来再探索。