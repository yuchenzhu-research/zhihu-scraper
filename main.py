import asyncio
import re
import sys
import time
import functools
from datetime import datetime
from pathlib import Path
from typing import Optional
from concurrent.futures import ThreadPoolExecutor

import questionary
from questionary import Style
from rich.console import Console, Group
from rich.panel import Panel
from rich.table import Table
from rich.align import Align
from rich.text import Text
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TaskProgressColumn
from rich import box
from rich.live import Live

from core.converter import ZhihuConverter
from core.scraper import ZhihuDownloader, PROXY_SERVER

# ==========================================
# æ ¸å¿ƒé…è‰²ç³»ç»Ÿ (Theme Tokens)
# ==========================================
THEME = {
    "accent": "#00C8FF",    # éœ“è™¹è“
    "secondary": "#FF1493", # äº®æ¡ƒçº¢
    "warn": "#EBFF3B",      # äº®é»„
    "text": "#FFFFFF",      # çº¯ç™½
    "dim": "#666666",       # æš—ç°
    "success": "#00FF55"    # è§å…‰ç»¿
}

# åˆå§‹åŒ– Rich Console
console = Console()
executor = ThreadPoolExecutor(max_workers=1)

# Questionary æ ·å¼
q_style = Style([
    ('question', f'fg:{THEME["accent"]} bold'),
    ('answer', f'fg:{THEME["success"]}'),
    ('pointer', f'fg:{THEME["secondary"]} bold'),
    ('highlighted', f'fg:{THEME["accent"]} bold'),
    ('selected', f'fg:{THEME["success"]}'),
    ('separator', f'fg:{THEME["dim"]}'),
    ('instruction', f'fg:{THEME["dim"]}'),
])
executor = ThreadPoolExecutor(max_workers=1)

# ==========================================
# æ‰¹é‡ä¸‹è½½åˆ—è¡¨ (ä¸æƒ³ç”¨å‘½ä»¤è¡Œè¾“å…¥æ—¶ï¼Œåœ¨è¿™é‡Œå¡«å…¥é“¾æ¥)
# ==========================================
BATCH_URLS = []

DATA_DIR = Path(__file__).parent / "data"

async def _async_input(prompt_text: str) -> str:
    """å°è£… rich çš„ console.input ä¸ºå¼‚æ­¥æ¨¡å¼ï¼Œå¸¦æœ‰ç°ä»£æ„Ÿçš„ Promptã€‚"""
    full_prompt = Text.assemble(
        (f" â¯ ", f"bold {THEME['secondary']}"),
        (prompt_text, f"bold {THEME['accent']}")
    )
    loop = asyncio.get_event_loop()
    # ä½¿ç”¨ ThreadPoolExecutor è¿è¡ŒåŒæ­¥çš„ console.input
    return await loop.run_in_executor(executor, console.input, full_prompt)


# â”€â”€ å·¥å…·å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def sanitize_filename(name: str) -> str:
    """æ¸…ç†æ–‡ä»¶åå¸¸ç”¨éæ³•å­—ç¬¦ã€‚"""
    name = re.sub(r'[/\\:*?"<>|\x00-\x1f]', "_", name)
    name = name.strip(" .")
    if len(name) > 50:
        name = name[:50].rstrip(" .")
    return name or "untitled"


def extract_urls(text: str) -> list[str]:
    """ä»æ–‡æœ¬ä¸­æå–çŸ¥ä¹é“¾æ¥ï¼Œæ”¯æŒä¸å¸¦ https:// çš„è¾“å…¥ã€‚"""
    # å…è®¸åè®®å¤´å¯é€‰
    pattern = r"(?:https?://)?(?:www\.|zhuanlan\.)?zhihu\.com/(?:p/\d+|question/\d+(?:/answer/\d+)?)"
    matches = re.findall(pattern, text)
    results = []
    for m in matches:
        if not m.startswith("http"):
            m = "https://" + m
        results.append(m)
    return list(dict.fromkeys(results))


def _print_banner():
    """æ‰“å°ç¬¦åˆ Americana Fusion é£æ ¼çš„ Dashboard Headerã€‚"""
    # é¡¶éƒ¨è£…é¥°å™¨
    top_deco = Text("âš¡ MODULE: DATA_EXTRACTION_UNIT âš¡", style=f"bold {THEME['accent']}")
    
    # çŸ¥ä¹ (Neon Branding)
    zhihu_header = Text("â–ˆ çŸ¥ ä¹ â–ˆ", style=f"bold {THEME['secondary']}")
    
    # SCRAPER (Refined Slant Art)
    scraper_art = r"""
   _____ __________  ___    ____  __________ 
  / ___// ____/ __ \/   |  / __ \/ ____/ __ \
  \__ \/ /   / /_/ / /| | / /_/ / __/ / /_/ /
 ___/ / /___/ _, _/ ___ |/ ____/ /___/ _, _/ 
/____/\____/_/ |_/_/  |_/_/   /_____/_/ |_|  
""".strip("\n")

    # åº•éƒ¨å…ƒæ•°æ®
    bot_deco = Text("INTELLIGENT CRAWLER ENGINE", style=f"{THEME['dim']} italic")
    
    # ç»„åˆ Banner
    header_content = Group(
        Align.center(top_deco),
        Align.center(zhihu_header),
        Align.center(Text(scraper_art, style=f"bold {THEME['accent']}")),
        Align.center(bot_deco)
    )
    
    header_panel = Panel(
        header_content,
        border_style=THEME["accent"],
        box=box.ROUNDED,
        padding=(1, 2),
        width=70
    )

    # Status Panel (æ¨ªå‘å•è¡Œ)
    proxy_status = f"[{THEME['success']}]ON[/]" if PROXY_SERVER else f"[{THEME['dim']}]OFF[/]"
    cookie_status = f"[{THEME['success']}]VALID[/]" if Path("cookies.json").exists() else f"[{THEME['warn']}]MISSING[/]"
    
    status_line = Text.assemble(
        " ğŸ”— ", ("GATEWAY: ", THEME["accent"]), (proxy_status, ""),
        "  |  ",
        " ğŸ”‘ ", ("SEAL: ", THEME["accent"]), (cookie_status, ""),
        "  |  ",
        " ğŸ“‚ ", ("ARCHIVE: ", THEME["accent"]), (str(DATA_DIR), THEME["text"]),
        "  |  ",
        " ğŸ•¸ï¸ ", ("CORE: ", THEME["accent"]), (f"[{THEME['secondary']}]LINKED[/]", "")
    )
    
    status_panel = Panel(
        Align.center(status_line),
        border_style=THEME["dim"],
        box=box.HORIZONTALS,
        padding=(0, 1),
        width=70
    )

    console.print(Align.center(header_panel))
    console.print(Align.center(status_panel))
    console.print("\n")


async def parse_question_options(url: str) -> dict:
    """äº¤äº’å¼è§£æé—®é¢˜æŠ“å–é€‰é¡¹ã€‚"""
    
    # 1. æ£€æŸ¥ Cookie (å¤ç”¨ downloader çš„é€»è¾‘)
    downloader = ZhihuDownloader(url)
    if not downloader.has_valid_cookies():
        console.print("[yellow]âš ï¸  æœªæ£€æµ‹åˆ°æœ‰æ•ˆç™»å½•ä¿¡æ¯ (z_c0)ï¼Œå¼ºåˆ¶ä½¿ç”¨æ¸¸å®¢æ¨¡å¼ (Top 3)[/yellow]")
        return {"start": 0, "limit": 3}

    # 2. äº¤äº’èœå• (å¼‚æ­¥)
    choice = await questionary.select(
        "è¯·é€‰æ‹©æŠ“å–æ¨¡å¼:",
        choices=[
            "1. æŒ‰æ•°é‡æŠ“å– (Top N)",
            "2. æŒ‰èŒƒå›´æŠ“å– (Start -> End)",
            "3. è¿”å›é»˜è®¤ (Top 3)"
        ],
        style=q_style
    ).ask_async()
    
    if not choice: # Ctrl+C
        return {"start": 0, "limit": 3}
        
    if choice.startswith("1"):
        limit = await questionary.text(
            "è¯·è¾“å…¥æŠ“å–æ•°é‡:",
            default="20",
            validate=lambda text: text.isdigit() and int(text) > 0 or "è¯·è¾“å…¥æ­£æ•´æ•°",
            style=q_style
        ).ask_async()
        return {"start": 0, "limit": int(limit) if limit else 3}
        
    elif choice.startswith("2"):
        console.print(f"[{THEME['dim']}]æç¤º: æ”¯æŒè¾“å…¥ 'ç­”ä¸»åå­—' æˆ– 'å›ç­”é“¾æ¥/ID'[/]")
        start = await questionary.text("èµ·å§‹é”šç‚¹ (Start):", style=q_style).ask_async()
        end = await questionary.text("ç»“æŸé”šç‚¹ (End):", style=q_style).ask_async()
        
        s_anchor = _parse_anchor(start)
        e_anchor = _parse_anchor(end)
        
        if s_anchor and e_anchor:
            return {
                "start": 0, "limit": 3,
                "start_anchor": s_anchor,
                "end_anchor": e_anchor
            }
        else:
            console.print("[red]âŒ é”šç‚¹è§£æå¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤æ¨¡å¼[/red]")
            return {"start": 0, "limit": 3}
            
    return {"start": 0, "limit": 3}


def _parse_anchor(val: str) -> Optional[dict]:
    if not val: return None
    m = re.search(r"answer/(\d+)", val)
    if m: return {"type": "answer_id", "value": m.group(1)}
    return {"type": "author", "value": val}


# â”€â”€ æµæ°´çº¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class Pipeline:
    def __init__(self, url: str, output_dir: Path = DATA_DIR, scrape_config: Optional[dict] = None):
        self.url = url
        self.output_dir = output_dir
        self.scrape_config = scrape_config or {}
        self.summary = [] # è®°å½•ç»“æœç”¨äºè¡¨æ ¼å±•ç¤º

    async def run(self) -> list:
        downloader = ZhihuDownloader(self.url)
        
        # ä½¿ç”¨è‡ªå®šä¹‰çš„ Progress
        progress = Progress(
            SpinnerColumn(style=THEME["secondary"]),
            TextColumn("[bold white]{task.description}"),
            BarColumn(complete_style=THEME["accent"], finished_style=THEME["success"]),
            TaskProgressColumn(),
            expand=True
        )

        with Live(progress, console=console, refresh_per_second=10):
            task_id = progress.add_task("ğŸš€ Extracting knowledge...", total=None)
            data = await downloader.fetch_page(**self.scrape_config)
            progress.update(task_id, description="ğŸ“¦ Data received, starting conversion...")

            if isinstance(data, list):
                progress.update(task_id, total=len(data))
                for item in data:
                    progress.update(task_id, description=f"ğŸ“ Converting: {item['title'][:20]}...")
                    res = await self._process_one(item, downloader.page_type)
                    self.summary.append(res)
                    progress.advance(task_id)
            else:
                res = await self._process_one(data, downloader.page_type)
                self.summary.append(res)
                progress.update(task_id, completed=1, total=1)
            
            progress.update(task_id, description="âœ¨ Task completed!")
            
        return self.summary

    async def _process_one(self, info: dict, page_type: str) -> dict:
        title = info["title"]
        author = info["author"]
        html = info["html"]
        
        # ç»“æœå¯¹è±¡
        result = {
            "title": title,
            "author": author,
            "status": "âœ… æˆåŠŸ",
            "path": ""
        }

        try:
            today = datetime.now().strftime("%Y-%m-%d")
            safe_title = sanitize_filename(title)
            safe_author = sanitize_filename(author)

            if page_type == "question":
                folder_name = sanitize_filename(f"[{today}] {title}")
                file_name = f"{safe_author}.md"
            else:
                date_str = info.get("date", today)
                folder_name = sanitize_filename(f"[{date_str}] {title} - {author}")
                file_name = "index.md"

            folder = self.output_dir / folder_name
            img_dir = folder / "images"
            folder.mkdir(parents=True, exist_ok=True)

            # ä¸‹è½½å›¾ç‰‡
            img_urls = ZhihuConverter.extract_image_urls(html)
            img_map = {}
            if img_urls:
                # è¿™é‡Œçš„ print ä¼šæ‰“æ–­ progress barï¼Œä½†åœ¨ single item æ—¶æ²¡å…³ç³»
                # ä¸ºäº†å®Œç¾ï¼Œè¿™é‡Œå…ˆé™é»˜ä¸‹è½½æˆ–ç®€å•è¾“å‡º
                img_map = await ZhihuDownloader.download_images(img_urls, img_dir)

            # HTML -> Markdown
            converter = ZhihuConverter(img_map=img_map)
            md = converter.convert(html)

            # ä¿å­˜
            header = (
                f"# {title}\n\n"
                f"> **ä½œè€…**: {author}  \n"
                f"> **æ¥æº**: [{self.url}]({self.url})  \n"
                f"> **æ—¥æœŸ**: {today}\n\n"
                f"---\n\n"
            )
            out_path = folder / file_name
            out_path.write_text(header + md, encoding="utf-8")
            
            # æ¸…ç†ç©ºç›®å½•
            if img_dir.exists() and not any(img_dir.iterdir()):
                img_dir.rmdir()
                
            # è®°å½•ç›¸å¯¹è·¯å¾„
            try:
                result["path"] = str(out_path.relative_to(Path.cwd()))
            except:
                result["path"] = str(out_path)
                
        except Exception as e:
            result["status"] = f"âœ˜ Failed: {str(e)[:20]}"
        
        return result


# â”€â”€ ä¸»å¾ªç¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def main() -> None:
    _print_banner()
    
    while True:
        # è·å–è¾“å…¥
        if BATCH_URLS:
            console.print(f"[bold yellow]ğŸ“‹ æ£€æµ‹åˆ°æ‰¹é‡ä»»åŠ¡ ({len(BATCH_URLS)} ä¸ª)[/bold yellow]")
            urls = list(BATCH_URLS)
            BATCH_URLS.clear()
        else:
            # ä½¿ç”¨ rich åŸç”Ÿ input çš„å°è£…ç‰ˆï¼Œå½»åº•è§£å†³ ghost prompt å†²çªé—®é¢˜
            answer = await _async_input("è¯·è¾“å…¥çŸ¥ä¹é“¾æ¥ (æˆ– 'q' é€€å‡º): ")
            
            if not answer or answer.strip().lower() == 'q':
                console.print(f"[{THEME['dim']}]Shutting down...[/]")
                time.sleep(0.3)
                break
            
            answer = answer.strip()
            urls = extract_urls(answer)
            
        if not urls:
            if answer and answer.lower() != 'q':
                # æ‰¹é‡ä»»åŠ¡æ— éœ€æŠ¥é”™ï¼Œæ­£å¸¸å¾ªç¯
                if not BATCH_URLS:
                    console.print("[red]âŒ æœªè¯†åˆ«åˆ°æœ‰æ•ˆé“¾æ¥ï¼Œè¯·é‡è¯•[/red]")
            continue
            
        # å¤„ç†é“¾æ¥
        console.rule(f"[bold {THEME['accent']}]Processing {len(urls)} Task(s)[/]")
        
        all_results = []
        
        for url in urls:
            scrape_config = {}
            if "/question/" in url and "/answer/" not in url:
                console.print(f"\n[{THEME['accent']}]âš™ï¸  Question detected:[/][dim] {url}[/]")
                scrape_config = await parse_question_options(url)
            
            try:
                pipeline = Pipeline(url, scrape_config=scrape_config)
                results = await pipeline.run()
                all_results.extend(results)
            except Exception as e:
                console.print(f"[bold {THEME['secondary']}]âœ˜ Critical Error:[/][red] {e}[/]")
        
        # æ‰“å°æ±‡æ€»è¡¨æ ¼
        if all_results:
            table = Table(
                title=f"[{THEME['success']}]âœ” Task Execution Summary[/]", 
                box=box.ROUNDED,
                header_style=f"bold {THEME['accent']}"
            )
            table.add_column("Author/Title", style="dim")
            table.add_column("Status", justify="center")
            table.add_column("Path", style=THEME["success"])
            
            for res in all_results:
                status_color = THEME["success"] if "âœ”" in res['status'] else THEME["secondary"]
                table.add_row(
                    f"{res['author']}\n[dim]{res['title'][:25]}...[/dim]",
                    f"[{status_color}]{res['status']}[/]",
                    res['path']
                )
            
            console.print(Align.center(table))
            console.print("\n")

if __name__ == "__main__":
    try:
        with console.status("âš¡ [bold]System Initializing...[/bold]", spinner="aesthetic"):
            time.sleep(0.5)
        asyncio.run(main())
    except KeyboardInterrupt:
        console.print(f"\n[{THEME['dim']}]Operation cancelled by user. Shutting down...[/]")
        time.sleep(0.3)