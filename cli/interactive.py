"""
cli/interactive.py â€” äº¤äº’å¼é¢æ¿æ¨¡å— (Americana Fusion é£æ ¼)

ç»§æ‰¿æ—§ç‰ˆ main.py çš„ç»šä¸½ç»ˆç«¯ Dashboardï¼Œå¹¶å¯¹æ¥ v3.0 çš„ db å¼•æ“ã€‚
"""

import asyncio
import re
import time
from pathlib import Path
from typing import Optional, List
from concurrent.futures import ThreadPoolExecutor

import questionary
from questionary import Style
from rich.console import Console, Group
from rich.panel import Panel
from rich.table import Table
from rich.align import Align
from rich.text import Text
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TaskProgressColumn
from rich import box
from rich.live import Live

from core.config import get_config, get_logger
from core.scraper import ZhihuDownloader
from cli.app import _fetch_and_save

# ==========================================
# åˆå§‹åŒ–é…ç½®å’Œæ—¥å¿—
# ==========================================
cfg = get_config()
log = get_logger()

# ==========================================
# æ ¸å¿ƒé…è‰²ç³»ç»Ÿ (Theme Tokens)
# ==========================================
THEME = {
    "accent": "#00C8FF",    # éœ“è™¹è“
    "secondary": "#FF1493", # äº®æ¡ƒçº¢
    "warn": "#EBFF3B",      # äº®é»„
    "text": "#FFFFFF",      # çº¯ç™½
    "dim": "#666666",       # æš—ç°
    "success": "#00FF55"    # è§å…‰ç»¿
}

console = Console()
executor = ThreadPoolExecutor(max_workers=1)

q_style = Style([
    ('question', f'fg:{THEME["accent"]} bold'),
    ('answer', f'fg:{THEME["success"]}'),
    ('pointer', f'fg:{THEME["secondary"]} bold'),
    ('highlighted', f'fg:{THEME["accent"]} bold'),
    ('selected', f'fg:{THEME["success"]}'),
    ('separator', f'fg:{THEME["dim"]}'),
    ('instruction', f'fg:{THEME["dim"]}'),
])

DATA_DIR = Path(cfg.output.directory)

async def _async_input(prompt_text: str) -> str:
    """å°è£… rich çš„ console.input ä¸ºå¼‚æ­¥æ¨¡å¼"""
    full_prompt = Text.assemble(
        (f" â¯ ", f"bold {THEME['secondary']}"),
        (prompt_text, f"bold {THEME['accent']}")
    )
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, console.input, full_prompt)

def extract_urls(text: str) -> List[str]:
    """ä»æ–‡æœ¬ä¸­æå–çŸ¥ä¹é“¾æ¥"""
    pattern = r"(?:https?://)?(?:www\.|zhuanlan\.)?zhihu\.com/(?:p/\d+|question/\d+(?:/answer/\d+)?)"
    matches = re.findall(pattern, text)
    results = []
    for m in matches:
        if not m.startswith("http"):
            m = "https://" + m
        results.append(m)
    return list(dict.fromkeys(results))

def _print_banner():
    """æ‰“å°ç¬¦åˆ Americana Fusion é£æ ¼çš„ Dashboard Header"""
    top_deco = Text("âš¡ MODULE: DATA_EXTRACTION_UNIT âš¡", style=f"bold {THEME['accent']}")
    zhihu_header = Text("â–ˆ çŸ¥ ä¹ â–ˆ", style=f"bold {THEME['secondary']}")
    scraper_art = r"""
   _____ __________  ___    ____  __________ 
  / ___// ____/ __ \/   |  / __ \/ ____/ __ \
  \__ \/ /   / /_/ / /| | / /_/ / __/ / /_/ /
 ___/ / /___/ _, _/ ___ |/ ____/ /___/ _, _/ 
/____/\____/_/ |_/_/  |_/_/   /_____/_/ |_|  
""".strip("\n")

    bot_deco = Text("INTELLIGENT CRAWLER ENGINE (v3.0 DB-LINKED)", style=f"{THEME['dim']} italic")
    
    header_content = Group(
        Align.center(top_deco),
        Align.center(zhihu_header),
        Align.center(Text(scraper_art, style=f"bold {THEME['accent']}")),
        Align.center(bot_deco)
    )
    
    header_panel = Panel(
        header_content, border_style=THEME["accent"], box=box.ROUNDED, padding=(1, 2), width=70
    )

    cookie_status = f"[{THEME['success']}]VALID[/]" if Path("cookies.json").exists() else f"[{THEME['warn']}]MISSING[/]"
    
    status_line = Text.assemble(
        " ğŸ”‘ ", ("SEAL: ", THEME["accent"]), (cookie_status, ""), "  |  ",
        " ğŸ“‚ ", ("ARCHIVE: ", THEME["accent"]), (f"[{THEME['success']}]SQLite + FS[/]", ""), "  |  ",
        " ğŸ•¸ï¸ ", ("CORE: ", THEME["accent"]), (f"[{THEME['secondary']}]API PROTOCOL[/]", "")
    )
    
    status_panel = Panel(
        Align.center(status_line), border_style=THEME["dim"], box=box.HORIZONTALS, padding=(0, 1), width=70
    )

    console.print(Align.center(header_panel))
    console.print(Align.center(status_panel))
    console.print("\n")

async def parse_question_options(url: str) -> dict:
    """äº¤äº’å¼è§£æé—®é¢˜æŠ“å–é€‰é¡¹"""
    downloader = ZhihuDownloader(url)
    if not downloader.has_valid_cookies():
        console.print("[yellow]âš ï¸  æœªæ£€æµ‹åˆ°æœ‰æ•ˆç™»å½•ä¿¡æ¯ (z_c0)ï¼Œå¼ºåˆ¶ä½¿ç”¨æ¸¸å®¢æ¨¡å¼ (Top 3)[/yellow]")
        return {"start": 0, "limit": 3}

    choice = await questionary.select(
        "è¯·é€‰æ‹©æŠ“å–æ¨¡å¼:",
        choices=["1. æŒ‰æ•°é‡æŠ“å– (Top N)", "2. è¿”å›é»˜è®¤ (Top 3)"],
        style=q_style
    ).ask_async()
    
    if not choice:
        return {"start": 0, "limit": 3}
        
    if choice.startswith("1"):
        limit = await questionary.text(
            "è¯·è¾“å…¥æŠ“å–æ•°é‡:", default="20",
            validate=lambda text: text.isdigit() and int(text) > 0 or "è¯·è¾“å…¥æ­£æ•´æ•°",
            style=q_style
        ).ask_async()
        return {"start": 0, "limit": int(limit) if limit else 3}
            
    return {"start": 0, "limit": 3}

# ==========================================
# äº¤äº’å¼ä¸»å…¥å£
# ==========================================

async def run_interactive():
    _print_banner()
    
    while True:
        answer = await _async_input("è¯·è¾“å…¥çŸ¥ä¹é“¾æ¥ (æˆ– 'q' é€€å‡º): ")
        
        if not answer or answer.strip().lower() == 'q':
            console.print(f"[{THEME['dim']}]Shutting down...[/]")
            time.sleep(0.3)
            break
        
        answer = answer.strip()
        urls = extract_urls(answer)
        
        if not urls:
            if answer and answer.lower() != 'q':
                console.print("[red]âŒ æœªè¯†åˆ«åˆ°æœ‰æ•ˆé“¾æ¥ï¼Œè¯·é‡è¯•[/red]")
            continue
            
        console.rule(f"[bold {THEME['accent']}]Processing {len(urls)} Task(s)[/]")
        
        for url in urls:
            scrape_config = {}
            if "/question/" in url and "/answer/" not in url:
                console.print(f"\n[{THEME['accent']}]âš™ï¸  Question detected:[/][dim] {url}[/]")
                scrape_config = await parse_question_options(url)
            
            try:
                progress = Progress(
                    SpinnerColumn(style=THEME["secondary"]),
                    TextColumn("[bold white]{task.description}"),
                    BarColumn(complete_style=THEME["accent"], finished_style=THEME["success"]),
                    TaskProgressColumn(),
                    expand=True
                )
                with Live(progress, console=console, refresh_per_second=10):
                    task_id = progress.add_task("ğŸš€ Extracting and Saving to Database...", total=None)
                    
                    # è°ƒç”¨å¸¦æœ‰æ•°æ®åº“å­˜å‚¨çš„åº•å±‚æ ¸å¿ƒç®¡é“
                    await _fetch_and_save(
                        url=url,
                        output_dir=DATA_DIR,
                        scrape_config=scrape_config,
                        download_images=True,
                        headless=True
                    )
                    
                    progress.update(task_id, completed=1, total=1, description="âœ¨ Task completed and DB synced!")
            except Exception as e:
                console.print(f"[bold {THEME['secondary']}]âœ˜ Critical Error:[/][red] {e}[/]")

        # ç»™ç”¨æˆ·ä¸€å°æ®µåœé¡¿é˜…è¯»ç»“æœ
        print("\n")
