# 如何评价 BERT 模型？

> **作者**: 宫一尘  
> **来源**: [https://www.zhihu.com/question/298203515](https://www.zhihu.com/question/298203515)  
> **日期**: 2026-02-21

---

如果说这是里程碑式的工作的话，那我在Google实习期间真的是见证了历史。

每周和Jacob一起开会，他复现openAI的带预训练语言模型的GPT只花费了一周，同时发现效果不如预期。拿到大数据，重新训练定位出问题只花了两天。再下次开会他的新想法已经超过openAI模型了。再下周开会就有了现在Single Model在几个任务上的成绩。

请你认真地感受一下这个速度。OpenAI做他们的工作的时候预训练他们的语言模型花了一个月，而Jacob用TPU只花了一天。OpenAI训练语言模型基本是按照原来Transformer的配置，调整了一些参数，而Jacob可以随心所欲地尝试自己新的想法。这是超强算力和超强工程能力碰撞而迸发的能量！未来真的是算力的时代。

[@林洲汉](https://www.zhihu.com/people/833e12945579894a209a85ad6c73b920) 作为共同见证者，你也来膜一下？
